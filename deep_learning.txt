!rm -rf /kaggle/working/*

import os
import numpy as np
import pandas as pd
import random
import cv2
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import ResNet50, EfficientNetB0, MobileNetV2

import albumentations as A
from tqdm import tqdm

DATASET_PATH = "/kaggle/input/date-palm-data/Date Palm data"

categories = ["healthy", "brown spots", "white scale"]
data = []

for category in categories:
    folder_path = os.path.join(DATASET_PATH, category)
    for filename in os.listdir(folder_path):
        data.append([os.path.join(folder_path, filename), category])

df = pd.DataFrame(data, columns=["image", "label"])
print(f"Dataset Loaded! Total Images: {len(df)}")
df.head()
category_counts = df["label"].value_counts()
print("Number of images per category:")
print(category_counts)

plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.index, y=category_counts.values, palette="viridis")
plt.xlabel("Category")
plt.ylabel("Number of Images")
plt.title("Class Distribution Before Augmentation")
plt.show()

AUGMENTED_PATH = "/kaggle/working/augmented_data"

augmentor = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=40, p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.GaussNoise(p=0.3),
    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, p=0.5),
    A.GaussianBlur(p=0.2),
])

if not os.path.exists(AUGMENTED_PATH):
    os.makedirs(AUGMENTED_PATH)

def augment_images(df, target_size=8000):
    new_data = []
    for category in categories:
        cat_df = df[df["label"] == category]
        count = len(cat_df)
        img_paths = cat_df["image"].tolist()

        output_folder = os.path.join(AUGMENTED_PATH, category)
        os.makedirs(output_folder, exist_ok=True)

        while count < target_size:
            img_path = random.choice(img_paths)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            augmented = augmentor(image=img)["image"]

            new_filename = f"{category}_{count}.jpg"
            new_path = os.path.join(output_folder, new_filename)
            cv2.imwrite(new_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))
            new_data.append([new_path, category])
            count += 1

    return new_data

augmented_data = augment_images(df)
df_augmented = pd.DataFrame(augmented_data, columns=["image", "label"])
df = pd.concat([df, df_augmented], ignore_index=True)

print(f"Data Augmentation Completed! Total Images: {len(df)}")

category_counts = df["label"].value_counts()
print("Number of images per category after augmentation:")
print(category_counts)

plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.index, y=category_counts.values, palette="coolwarm")
plt.xlabel("Category")
plt.ylabel("Number of Images")
plt.title("Class Distribution After Augmentation")
plt.show()

train_df, test_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df["label"], random_state=42)

print(f"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}")

IMG_SIZE = (224, 224)
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(rescale=1.0/255.0)
val_datagen = ImageDataGenerator(rescale=1.0/255.0)

train_generator = train_datagen.flow_from_dataframe(
    train_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)
val_generator = val_datagen.flow_from_dataframe(
    val_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)
test_generator = val_datagen.flow_from_dataframe(
    test_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical", shuffle=False
)

def build_model(base_model):
    base_model.trainable = False  # Freeze base model layers
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(128, activation="relu"),
        Dropout(0.5),
        Dense(3, activation="softmax")
    ])
    model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])
    return model

resnet_model = build_model(ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3)))
effnet_model = build_model(EfficientNetB0(weights="imagenet", include_top=False, input_shape=(224, 224, 3)))

history_resnet = resnet_model.fit(train_generator, validation_data=val_generator, epochs=10)
history_effnet = effnet_model.fit(train_generator, validation_data=val_generator, epochs=10)

def ensemble_predict(models, test_generator):
    preds = [model.predict(test_generator) for model in models]
    avg_preds = np.mean(preds, axis=0)
    return np.argmax(avg_preds, axis=1)

y_true = test_generator.classes
y_pred = ensemble_predict([resnet_model, effnet_model], test_generator)

conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=categories, yticklabels=categories)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Evaluate ResNet50 model
test_loss_resnet, test_acc_resnet = resnet_model.evaluate(test_generator)
print(f"ResNet50 Test Accuracy: {test_acc_resnet:.4f}")

# Evaluate EfficientNet model
test_loss_effnet, test_acc_effnet = effnet_model.evaluate(test_generator)
print(f"EfficientNetB0 Test Accuracy: {test_acc_effnet:.4f}")

from sklearn.metrics import accuracy_score

# Get true labels
y_true = test_generator.classes

# Get ensemble predictions
y_pred = ensemble_predict([resnet_model, effnet_model], test_generator)

# Compute accuracy
ensemble_accuracy = accuracy_score(y_true, y_pred)
print(f"Ensemble Model Test Accuracy: {ensemble_accuracy:.4f}")
