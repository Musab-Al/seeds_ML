import os
import numpy as np
import pandas as pd
import random
import cv2
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
import albumentations as A
from tqdm import tqdm


# Define dataset path
DATASET_PATH = "/kaggle/input/date-palm-data/Date Palm data"

# Define categories (subfolder names)
categories = ["healthy", "brown spots", "white scale"]

# Create dataframe
data = []
for category in categories:
    folder_path = os.path.join(DATASET_PATH, category)
    for filename in os.listdir(folder_path):
        data.append([os.path.join(folder_path, filename), category])

df = pd.DataFrame(data, columns=["image", "label"])
print("Dataset Loaded! Total Images:", len(df))

# Display first few rows
df.head()
category_counts = df["label"].value_counts()
print("Number of images per category:")
print(category_counts)

# Plot distribution
plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.index, y=category_counts.values, palette="viridis")
plt.xlabel("Category")
plt.ylabel("Number of Images")
plt.title("Class Distribution Before Augmentation")
plt.show()

AUGMENTED_PATH = "/kaggle/working/augmented_data"

# Define augmentation pipeline
augmentor = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=40, p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.GaussNoise(p=0.3),
    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, p=0.5),
    A.GaussianBlur(p=0.2),
])

# Create directory for augmented images
if not os.path.exists(AUGMENTED_PATH):
    os.makedirs(AUGMENTED_PATH)

# Function to perform augmentation
def augment_images(df, target_size=8000):
    new_data = []
    for category in categories:
        cat_df = df[df["label"] == category]
        count = len(cat_df)
        img_paths = cat_df["image"].tolist()

        output_folder = os.path.join(AUGMENTED_PATH, category)
        os.makedirs(output_folder, exist_ok=True)

        while count < target_size:
            img_path = random.choice(img_paths)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            augmented = augmentor(image=img)["image"]

            new_filename = f"{category}_{count}.jpg"
            new_path = os.path.join(output_folder, new_filename)
            cv2.imwrite(new_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))
            new_data.append([new_path, category])
            count += 1

    return new_data

# Augment images
augmented_data = augment_images(df)
df_augmented = pd.DataFrame(augmented_data, columns=["image", "label"])
df = pd.concat([df, df_augmented], ignore_index=True)

print("Data Augmentation Completed! Total Images:", len(df))

category_counts = df["label"].value_counts()
print("Number of images per category after augmentation:")
print(category_counts)

# Plot updated distribution
plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.index, y=category_counts.values, palette="coolwarm")
plt.xlabel("Category")
plt.ylabel("Number of Images")
plt.title("Class Distribution After Augmentation")
plt.show()

train_df, test_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df["label"], random_state=42)

print(f"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}")

IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Data Generators
train_datagen = ImageDataGenerator(rescale=1.0/255.0)
val_datagen = ImageDataGenerator(rescale=1.0/255.0)

train_generator = train_datagen.flow_from_dataframe(
    train_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)
val_generator = val_datagen.flow_from_dataframe(
    val_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)
test_generator = val_datagen.flow_from_dataframe(
    test_df, x_col="image", y_col="label", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical", shuffle=False
)

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(train_generator, validation_data=val_generator, epochs=20)

test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc:.2f}")

y_true = test_generator.classes
y_pred = np.argmax(model.predict(test_generator), axis=1)

conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=categories, yticklabels=categories)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Save the trained model
model.save("date_palm_disease_model.h5")
print("Model saved successfully!")
